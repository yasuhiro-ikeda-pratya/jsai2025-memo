# 要約（gpt-4o）
## [3B1-KS-13] 希望ある未来に向けたAGIの安全性とアライメント
- AGIの定義、制御可能性、道具的収束や権力追求のリスク
- シンギュラリティ後の社会と倫理形成の展望
- 自律性の向上と制御困難性のジレンマ
- 電力問題、価値創出、BI構想までを広範に議論
- AGI社会の設計と希望の持てる共生の模索

## [3A2-PS-3] AIのリスクと安全性〜AI広島プロセスからAISI設立まで
- AI導入に伴う技術的・社会的リスクの整理
- 安全とは「許容不可なリスクがない」状態と定義
- AISI設立の背景と役割
- 国際協調・国内制度整備の動向
- 安全性評価の枠組み構築と実務的対応の必要性

## [3C4-KS-28] 万博関連企画：人文社会科学とAIの融合研究
- 犯罪心理・触覚技術・顧客理解など多分野との融合事例
- 被害心理推定やカスハラ対策でのAI応用
- 触れる3DCG技術とその感性価値の拡張
- バーチャル顧客の生成と行動分析によるマーケティング支援
- 社会的課題へのAI実装の現場を紹介

## [3B5-KS-15] 2050年の人とAIのあるべき共生社会について考える
- AI倫理賞の受賞事例紹介
- トラスト構築や擬人化の限界、倫理的設計の重要性
- SFや哲学的視点を交えた未来社会像の探求
- AIとの共生に必要な「覚悟」と「教育」の提示
- 人間とAIの関係性の再定義を目指す

## [3B6-KS-16] 労働における人間とAIとの共創
- HR・人事領域におけるAI活用と課題
- 転職支援、社内異動、職種間移動の最適化
- 意見集約AIによる多様性の確保
- 「活躍」の定量化に挑む試み
- データとAIを通じた働き方の未来像の提案

## [4B1-KS-19] ニュースデータｘAI・知の共創プロジェクト
- ニュースデータをAIで分析し社会課題を抽出
- AIマップを用いたキーワードネットワークの構築
- 時代背景を含めた意味づけの自動化に挑戦
- コンペ形式で実装例を推進

## [4B3-KS-21] 人とAIエージェントの共生・協働
- 自動交渉や集団行動のシミュレーション
- エージェント経済圏の可能性と社会実装の課題
- 合意形成支援、トラスト設計、安全性確保への挑戦
- LLMや制度設計と連携した社会構築ビジョン
- 共生に向けた倫理・数理・文化の接合点を模索

# メモ
#  [[3B1-KS-13] 希望ある未来に向けたAGIの安全性とアライメント](https://confit.atlas.jp/guide/event/jsai2025/session/3B01-01/tables?kjigNwnsCZ)
AIアライメントネットワーク（ALIGN）によるセッション
## AGI総論

- 人間とAIとAGIの混成系としての社会の健全性確保
- 「強いAI」「弱いAI」はAI研究者のスタンスの分類
	- 強い仮説、弱い仮説

- AGIの定義
	- 専門家の合意はない
	- Legg-Hutter知能指標
	- Legg-Hutter知能指標は計算可能なすべての環境に対してパレート最適となるのが万能AI
	- AGI<ASI<万能AI
	- AGIの制御可能性
		- 道具的収束
			- 自己保存、リソース確保、目標の保持、効率性の追求
		- 権力追求行動
	- エンパワメント
## AIアラインメント、Post Singularity

- シンギュラリティ：知能において人類を圧倒したAIが支配的になる状態への遷移
- シンギュラリティは止められない
	- 経済的・軍事的・政治的優位性の確保
- 存在論的トリアージ
	- 人類手の行動次第で結果が変わりうる世界にいると「信じる」
- ポストシンギュラリティ共生学
- NAIAビジョン
	- AI社会の自律的な倫理形成
- 全脳アーキテクチャ・イニシアティブ
	- NeuroQuad Architecture
- 現在の状況は明治維新に近い
## AIの自律性と自発性
- Universal AI
- Legg-Hutter知能指標
	- 様々な環境下での報酬獲得能力を、環境系の単純さで割引しつつ合計した知能指数
- AIXI
- Self-AIXI
	- 究極エージェントに漸近していくAIエージェント
- Self-AIXIの報酬関数には変分エンパワーメント（≒自律性）の最大化が含まれる
- AGIに到達させるためにはAIの自律性を高める必要があるが、自律性を高めるとAIは言うことを聞かなくなる恐れがある

## AIの電力問題
- 逆PC革命
	- ユーザー端末からハイパースケールデータセンターへ
- 世界のDC電力消費量は全体の1.5%。2030年には2024年の倍以上になる想定（DC以外も含む）
- IEAの予想では「AIが電力を食い尽くす」ほどではない。ただし局所的な問題はある
- 上記予想はあくまでトレンドの外挿。実際にはどうなるかわからない
- 「訓練」よりも「推論」の方が電力がかかる
- 動画生成にはPC充電2回分の電力
- Hugging faceがAI energy scoreを公開
- 日本人の一人当たりの1秒の電力消費量は、ChatGPTの推論１回とほぼ同等
- 計算量を注ぎ込んで得られた知能から、どのような価値を得られているのか？

## ベーシックインカム
- プレ機械化経済（産業革命前）、機械化経済（産業革命以降）、純粋機械化経済（AGI出現以降）
	- 産業革命は資本集約度の上昇、AGIの出現は代替の弾力性が上昇
- 需要制約と資源制約
- BIに財源は必要ない
	- ハイパーデフレを避けるためにお金を配る必要があるので
- 科学技術力・経済力＝＞軍事力
- ソブリンAIの必要性。新本郷バレー計画
- 研究者を世界中から招聘するチャンス
## パネルディスカッション
- 自律性・脅威について
	- kill switchを押されないように行動することが確認されている（hayashi）
- AI開発のために国は国債をどの程度発行してよいのか
	- インフレになりさえしなければ良い。後で税金で回収するにしてもAIで生産性が上がればOK（inoue）
- 我々の日常はどう変わっていくか
	- 人の労働の価値が下がっていく。労働に変わる価値の理論化が必要。 
- 我々・ビッグテックは何をすべきか
	- ホワイトカラーとブルーカラーに対するマインドセットを変えるべき（inoue）
	- 理論研究をどう繋げていくのか（maruyama）
	- 一人NPO団体が出てくる（hayashi）
	- 人間とAIの共生を定式化（takahashi）
	- 人間同士が争っているとAIに裏切られる（yamakawa）
- JSAIへの提言
	- 楽観と悲観のバランス。希望を失わない（takahashi）
# [[3A2-PS-3] AIのリスクと安全性〜AI広島プロセスからAISI設立まで（村上 明子）](https://confit.atlas.jp/guide/event/jsai2025/session/3A06-06/tables?kjigNwnsCZ)
- 日本の労働生産性は低い。G7で最下位、OECDでも23位
- 保険会社におけるAIの活用
	- 損害調査の効率化
- AI安全性について
	- もしAIが間違っていたら。どのように「安全」とみなすのか
	- AIの最大のリスク、それはAIを恐れて使わないこと
		- 市場競争力がなくなるだけでなくイノベーションも加速できない
	- プライベート利用では「回答の不正確さ」、企業の利用では「情報漏洩」「回答の不正確さ」に対する不安が多い
	- 「安全」とは**許容不可**なリスクが無いこと、「安心」とは「心配・不安がないこと」
	- リスクは「技術的リスク」「社会的リスク」に大別される
		- 技術的リスク
			- 誤回答
				- チャットボットが誤って割引ありと表示。裁判の結果割引を実施するよう指示
			- データによるバイアス
				- アマゾンの採用AI、女性に不利。廃止
			- プロンプトインジェクション
		- 社会的リスク
			- 悪用
				- 生成AIを悪用しウィルス作成
				- 楽天モバイルに不正接続するプログラム生成
				- ディープフェイク
			- 生成AIとのチャット後に自殺
			- 著作権侵害
				- 「ジブリ風」は放置でよいのか？
			- レピュテーションリスク
				- プライバシー侵害。高校生の娘の妊娠を予測して関連商品をレコメンド
	- AI原則からAIガバナンスへ
		- 生成AIの登場により透明性・説明可能性が困難に。AI原則からAIガバナンスの必要性に進化
	- AIのデュアルユース
		- 特に軍事利用、バイオ、ケミカル分野での悪用が懸念
- AISI（AIセーフティ・インスティチュート）について
	- 統合イノベーション戦略2024においてAI安全性の中心機関と定義
	- 広島AIプロセス、AIセーフティサミットを経て設立
	- 役割：政府への支援、日本におけるAIセーフティのハブ、研究機関との連携
	- 業務：安全性評価とその実施手法に関する検討や国際連携に関する業務などを遂行
	- 成果物：AI事業者ガイドラインを軸に、技術的なレビューから人材育成まで、幅広く取り組む
	- AI提供者として、AIセーフティを対策することが不可欠
	- 評価観点ガイド・レッドチーミング手法ガイドを作成
	- 内閣府を事務局とする「AISI関係府省庁等連絡会議」で政府方針等を検討。AISI所長を委員長とする「AISI運営委員会」で事業方針を検討
- AISIパートナーシップ協定
	- 国研におけるAI安全性に関する研究
		- Web情報によるLLM出力の裏取り技術の研究開発（NICT）
		- LLM安全性評価データセット（NII）
	- LLM-jpの安全性についての取り組み
	- データ品質確保の取り組み（IPAデジタル基盤センター）
	- AIセーフティに関する活動マップ（AMAIS）
		- 見落とされがちな部分など、活動間の相関関係を全体像として可視化
	- 事業実証ワーキンググループの設置
		- 多様な民間全体の参加を目指す
- 国際協調の重要性
	- 国際の場に日本人があまりいない。ICLRに行ったが日本人いないし日本より皆若い
	- 各国ガイドラインの相互関係の確認、国際的に通用する各種ガイドラインの作成と好評、国際会合での合意形成が必要
	- AI安全性の観点では日本はリーディングカントリー
	- 広島AIプロセス・フレンズグループ
	- AISI国際ネットワーク・ミッションステートメント
		- 研究・テスト・ガイダンス・包摂
- 規制について
	- 日本のAI法「ソフトローアプローチをハードローで規定」
		- 厳しい罰則で規制する方向を目指すEU
		- 規制緩和でイノベーションを促進させる米国
		- 双方のいいとこ取りをしたのが日本
	- EUにおけるAI法
		- リスクベースの規制・高リスクAIへの義務・生成AIへの対応も明記・企業開発者への影響大
	- 米国のAI対策
		- 州によって規制が異なっていたが、政権交代に伴い大きく方針を転換。州レベルのAI規制について10年のモラトリアム期間を置く（無効にする）提案が下院から上院へ進捗
	- 日本でのAI制度に関する動き
		- AI戦略会議・AI制度研究会
		- AI法案が設立
			- 罰則は無いが、既存法で罰されるものは罰される
			- 罰則を作る規定も明記
- 技術動向
	- AIモデルレベルからシステムレベルで安全性を考える必要がある
	- リスク回避技術・バイアスへの対応
	- LLMガードレールの設置
# [[3C4-KS-28] 万博関連企画：人文社会科学とAIの融合研究](https://confit.atlas.jp/guide/event/jsai2025/session/3C02-02/tables?kjigNwnsCZ)
## オープニングセッション
- コンバージングテクノロジー
	- 従来のデジタル技術のみでは対策できない問題に対して、異分野を融合した技術で取り組む
	- （例）特殊詐欺対策。心理学に基づいて被害者側の心理状態を推定。ミリ波を用いて推定した心理状態から、騙されている状態を82%の精度で推定
## 犯罪心理学との融合におけるカスタマーハラスメント対策
- 心理学は長い過去を持っているが、短い歴史しか持っていない
	- 学問として認められたのは比較的最近
- 心理学と統計学：犯罪者プロファイリング
	- 過去の犯罪データと該当犯罪データの分析
	- 多変量解析などを用いた分析結果を、犯罪捜査の意思決定に反映させる
- 心理学と生理学：ポリグラフ検査
	- 自律神経系を測定
	- 今、現在の記憶（犯罪事実に関する事項）を検討する心理検査
	- 嘘は発見できない。犯人しか知らない本当の情報に関する質問と適当な質問をおこない、反応を分析する。ドキドキ反応はノイズ。抑制的反応を評価
	- 感度95%、特異度96%
- プロファイリング
	- FBI：精神医学や臨床心理学を背景。直感的。
	- カンターら：犯罪心理学や統計学を背景。再現性が高い。多変量解析
- 株式会社Singular Perturbations
	- CRIME NABI。過去に犯罪がおきた場所から次に起こる場所を予測
- カスタマーハラスメント
	- チェックリストの開発
		- カスハラ度チェックリスト
		- 対応者が苦痛かどうか。カスハラ・ストレッサー尺度
	- カスハラ被害の分析
		- UAゼンセン所属組合員。50%以上がカスハラ経験あり
		- 4グループに分類
			- スーパーマケット、ホテル、フード、パチンコ
	- 加害者への調査
		- 2060名中44.9%がカスハラ実施経験あり。カスハラ被害と同様にグループ化された
			- 被害意識型、歪んた正義感、プライド型、昭和のオヤジ型
			- 回避・防衛としての攻撃、影響・強制としての攻撃、制裁・報復としての攻撃、自己呈示としての攻撃
		- ストレスの発散にはなっていない。嫌な思いが残ったという答え多数
	- カスタマーハラスメント対応教育プログラムの構築
		- 業種・業態にあったカスタマーハラスメントAIで対応の練習
- JR西日本のカスタマーハラスメント対策ポリシーを書いている
## 触れる3DCG
- 触覚を生成する技術
- ロボット、手術、ゲーム向けに長く研究されていたが、なかなかうまく行っていなかった
	- 力や振動の再現はできていたが、触覚は困難
- weart。指で摘んだ感覚を再現
- 超音波を収束させて放射圧を発生させる技術は10年前にあった
	- 刺激が弱い、特殊な振動覚、2次元、機械刺激のみという課題が
- ブレークスルーの要点
	- 良好な触覚再現のためには収束の角度θを大きくすることが望ましい
	- 人間は圧覚が弱いが、10Hz以下で焦点を移動させることで圧覚を強く感じることができる
	- チクっとする感覚以外は再現できるように
- SXSW2024でデモ実施
	- 柔らかいものを触る撫でる感覚、雨が振る感覚を感じられる
- 万博「未来の都市パビリオン」で体験可能
- 電通デジタル Entouchable Museum
	- 超さわれる美術館
	- モナリザと触れ合う体験
- AIの活用
	- AIが無ければ状況に合わせた触覚刺激が作れない
	- AIが無ければ触覚を必要とする状況が作れない
- 触覚がもたらす2つの効果
	- 「存在感の伝達」と「Affective Touch」
		- VRペット
		- 視覚障害者とのインタラクション
		- 離れた人との触れ合い
		- 快の刺激の活用
- 「弁別的触覚」と「感情的触覚」
- 活用の可能性
	- ストレスコントロール、快眠への活用
	- 子どものメンタルヘルスへの活用
		- 触覚は情動に直結、経験が不要（経験にほぼ関係なく快・不快が決まっている）
- AIの適用分野
	- 最終的に人間が残らない応用（ロボットだけで完結する仕事）
	- 人間への働きかけを目的とする応用
		- どこまで人間を変えて良いのかは人間が決める必要あり。AI任せにはできない
## 生成AIによるAIバーチャル顧客の活用
- NTTデータ
- JALカードへの勧誘。データから顧客インサイトを発掘し新たなマーケティング
- 概要
	- JALカード会員をクラスタリングし、AIバーチャル顧客を生成
	- LITRON MASを活用してインタビューやグループディスカッションを実施
	- 販促プロモーションの購買率が3.0%向上
- 詳細
	- 会員データから類似した購買傾向を持つクラスタを作成
	- ルールベースでの代表会員の抽出
	- 生成AIで代表会員の特徴分析
	- 生成AIでカード会員のペルソナ化
	- インタビューの実施
		- インタビュー形式・質問の設計は人間が実施
		- インタビュー自体は生成AIが実施
	- グループディスカッション
		- 「誰が一番高級ワインを購入したいか」について、ペルソナを設定した生成AI同士で議論
	- ファシリテーター役の生成AIが各ペルソナの発言を要約、ワインを購入しそうなペルソナを選定
	- ペルソナに該当するクラスタのカード会員にプロモーション。従来のプロモーションに比べて購買率が3%向上
- プロモーション以外の活用については検討中
# [[3B5-KS-15] 倫理委員会特別企画「2050年の人とAIのあるべき共生社会について考える」](https://confit.atlas.jp/guide/event/jsai2025/session/3B03-03/tables?ZGqhQToSwn)
## AI ELSI賞
### Cross-Cultural Approaches to DesirableAI
- 国内外4大学のプロジェクト
- オンラインセミナーによる全世界同時対話型イベント
### 日本IBM AI倫理チーム
- ガイドライン策定活動・社内外での啓蒙活動
- 3年間の主要な活動
	- AI倫理診断・相談（年間数百件）
	- 教育パッケージ開発と教育実施
### ALIGN
- 超知能がある未来社会シナリオコンテスト
- 「2040年代の社会における超知能と人類の共生」をテーマとしたSFシナリオを募集
- 60件の応募。学生・ライター・社会人など幅広い層から応募
- 重要性・独善性・蓋然性で評価
	- SF作家（池澤春菜）・ALIGN会員等が審査
- 入選作・佳作はALIGNWebページで閲覧可能
### 科学技術の倫理的設計のための実践的AI技術の開発とその産業応用
- 倫理学・設計学・創造活動支援研究・データ利活用研究の融合
- 有機的で動的な設計支援ツール
- dfrome.org
	- 倫理的な目的に向けたシステム設計のツール
	- 実用例
		- 構造計画研究所：組織育成ダッシュボード
		- 村田製作所：モノづくり向けのData Leaf
		- 愛知産業大学高校連携DX事業
- hienar.com
	- インプット：グラフ生成のテーマ
	- アウトプット：設計アイデアの物語構造
## 討論（テーマ：未来志向で先を見よう！！人とAIとの共生の未来）
### 臨界状態から次の安定までのカオスをどう乗り切るか
- 道具から「おもてなし」そして「思いやり」へ（栗原）
	- 思いやりはメタな深いおもてなし。苦言も呈するし、拒否もする
- AIと人間の共生社会を基礎づけるのはトラスト？（中川）
	- 利己的なAI
		- AIが人間を使って自分を進化させている
		- そんな状況はあまり良くない
	- 自然人の集合が社会を形成し維持していくためにはトラストが必要
		- 自分の行為に対して相手がどう反応するかの期待
	- 依頼タスクの成否でトラストの許容範囲は増減する
		- 成功すると許容範囲は少し増す。失敗すると大きく減少
	- 人間が自律的AIを許容範囲Xでトラストしていることを自律的AIに伝えていると、許容範囲に入っていない場合にAIはどのような行動を取るか？
		- それを人間側に伝える？
	- 人間がAIをトラストするのとほぼ同じ構造で、AIも人間をトラストする
		- 許容度はAI側にだけある
	- そのような社会で生きていく覚悟が人間側にあるか
- AI時代の人はどうなる？（武田）
	- 世界にはAIエージェントが満ち溢れる。Intelligence Overload/Overflow
	- Intelligence Overload/Overflowへ対処
		- 人もAIで"武装"
		- その場合に人とAIのボーダーはどうなるのか？
	- AIと共存する「私」とは？
	- 人間と技術の関係性(Verbeek2011)
		- 身体的関係
			- サイボーグ関係（人間／技術）->（世界）
		- 解釈学的関係
			- 合成関係
		- 他社関係
		- 背景関係
		- AI社会関係：（人間／技術）->（技術／世界）
	- つながりが作る人
		- つながりが作る「わたし」
			- 他社の存在によってはじめてその姿をつかむことができる
	- 分人型社会
	- データ至上主義において
		- 「人間だけでなくあらゆるものをインターネットに接続しデータフローを最大化せよ」
	- その結果
		- 人は「データフローの一部」となる
- 技術は変わる、でも人間の選択は残る（高橋）
	- レクチャーシリーズ「AIと社会と人間」
		- SNSを中心とするAIのアルゴリズムが人々の心理や社会にもたらす問題を安全保障の観点から分析
	- ミッション・インポッシブルにおける「エンティティ」
		- 被中央集権的な自律分散型のモデルであるため、破壊や排除が非常に難しい
		- AIが脅威として見られている
	- 未来について何を望むのか
		- 「人とAIが共生する社会を目指すなら「こころ」を創るのは達成すべき課題」
- My life with YabaD'27（ジェブカ・ラファウ）
	- 2027年に購入したBuddy AI「コペルニクス」
	- ユーザー学習5日目に突然オヤジギャクを使い始めたので、違うペルソナを購入
		- MatchAI（松ちゃん）が面白かったので購入。YabaD
	- 結局13個のペルソナを利用
	- 秘書のAIが総長の秘書AIに恋をして私のプライベートな情報を流してしまった
### パネルディスカッション
- AIを擬人化しすぎていないか。擬人化を超えたイメージが持てると先が見えるのではないか（中川）
- 人間がAI漬けになる時代は確実に来る。そうすると外界と自分の境が分からなくなる。脳とAIが一体化した時にどこまでが自分なのかという問題が医学的・哲学的にも生じるはず（中川）
- 小学生向けのワークショップ。明らかにここ５〜６年で子どもとAIの距離は近づいている。AIネイティブの時代になりつつある（高橋）
- 「芸術的良心」は必ずしも人間の倫理と一致しない。「人間のための倫理」以外に向けた研究は存在しないのか（nakazawa）
	- 人工知能学会なのでフォーカスは「知能」。それが必ずしも人間のものではないディストピア的な研究も出てきてしまうかも
	- 「人間だけのethics」については疑い始めている（中川）
## 提言
- 生成AIの能力が飛躍的に向上し、社会で人間のパートナーの役割を果たすようになるでしょう。ただし、生成AIは本質的には人間とは異なる仕組みで動いており、人間と同じとみなしてはいけません。人とAIの違いを理解した上でAIを活用する必要があります。AIを使いこなすには、それ以上に我々にしっかりした思考力が求められます、。そのためにも、子供の頃から思考力を育む教育が必要であると考えます。

# [[3B6-KS-16] 労働における人間とAIとの共創 〜 人間とAIにまつわる新しい研究の探索](https://confit.atlas.jp/guide/event/jsai2025/session/3B04-04/tables?ZGqhQToSwn)
## シンギュレイト
- 静かなる退職（＝最低限の仕事）
- 人的資源（労働の量）・人的資本（労働の質）
- ジョブ型雇用
	- 専門性の重視→専門性の多様性
	- 副業の加速→働き方の多様性
	- マネジメントの必要性→多様性への対応
- 人事データを概観
	- 働く人と企業組織の計測
		- 心理学的計測、運動・行動、生体信号、企業組織の人間関係・ネットワーク
		- 計測頻度✕行動 or 心理。組織データ・社員データ・パフォーマンスデータ・行動データ・コミュニケーションデータ
		-  目的変数：経済成長・働きがい
- 企業組織は個人と集団のメゾな領域
## ミイダスHRサイエンス研究所
- ミイダス：転職支援アプリ。企業と求職者のマッチング
- HRサイエンス研究所
	- 推薦エンジン、企業文化分析、職種間距離
- 推薦システムによる転職支援
	- 目的
		- ユーザー（転職希望者）にアイテム（求人ポジション）への応募を促す
		- アイテムの表示順最適化
		- 応募数最大化→会社利益最大化
	- データ
		- ユーザー行動データ（閲覧、いいね、応募）
		- ユーザ特徴（デモグラ、希望待遇、希望職種、スキル、etc.）
		- アイテム特徴（デモグラ、待遇、職種、要求スキル、etc.）
	- 方法
		- パターン認識・機械学習
- 「活躍をつくる」を本気で狙うために推薦システムはどうあるべきか？
	- 「応募数最大化→会社利益最大化」が目的であってはいけない
	- 仮説
		- 職種・スキルもマッチング改善で活躍増大
		- 組織文化と個人特性のマッチング改善で活躍増大
- 異業種・異職種への転職
	- 職種をまたぐ転職は抵抗されがちだが、異業種転職で活躍を作りたい
		- 異業種転職は50%を超える
	- 職種遷移キャリアをグラフ表現することで、その次の転職先職種を予測するモデルを作成
- 職種・スキルの知識グラフDB構築
- 個人特性のアセスメントを用いたリクルーティング
	- 心理質問票・認知ゲーム・行動計測を元にアセスメント
- 社員アセスメントデータとハイパフォーマー分析
	- アセスメントのどの要因が上司評価につながっているか
	- 自社のハイパフォーマー要因を知る
	- 検定多重性の問題あり。新しい検定手法を提案
## 社内で働く人材のデータ（ビズリーチ）
- 人事における課題解決とデータ＆AI活用
- 社内の人事に期待される役割
	- 人事ファンクション自体の生産性向上
	- 人的資本経営
		- 「ヒト」への投資が投資家にとって重要
	- 一方で、人事を取り巻く状況はより複雑化
- 人事における課題
	- 採用・定着・育成・配置・労務
- 人材流出が経営課題に
- これまではKKDで乗り越えてきたが、KKDではスケールできない
- 人事KPIのデザイン
	- 人事にはKPIが圧倒的に足りていない
		- 「活躍」とは？
- 人員計画の実現
	- 社外からの調達→採用
	- 社内からの調達→異動
- 戦略的異動
	- データを活用した異動
		- パフォーマンス、多面評価、スキルギャップ、サクセッションプラン、エンゲージメント
- 社内版ビズリーチ
	- 社内でのマッチング
		- AIによるレジュメ作成・ポジション作成・レコメンド
- 客観性と効率性、潜在能力の発掘
- 戦略性とパフォーマンス
- あくまで人間の判断を「支援」するツール
## 多様性に配慮した意見集約AI（東大馬場先生）
- 単純な投票集約では多様な価値観が反映されない
	- 通常は得票数で選んだ候補から議論を通じて最終決定→多数派の価値観しか反映されない
- CrowDEA：多様な有望候補を選抜する投票集約法
	- 多様な有望候補が選ばれる
- 一対比較結果からPriority mapを生成
	- 入力：複数人の一対比較結果
	- 出力：Priority map
		- 各々の軸の中で最も良いものが外側に来る→外側の集合を集めることで多様な候補を抽出
	- 評価者の観点w_kと候補の潜在特徴x_iの内積から有望度をスコア化
	- 各候補は自身の最良観点v_iにおける有望度が他の候補の有望度よりも大きい
- オリンピックエンブレムでの適用例
	- 「現在的」と「伝統的」と解釈できる軸が出てきた
- CrowDEAを話し合いの場で使えないか
- 高校のクラスでの話し合い「グループワークで仕事をしない人がいる。どうしたらいい？」
	- CrowDEAを使わなかった場合：仕事をする人たちが議論をリード。一人必ず一つ仕事をするような役割分担をする方向に。仕事をしない人の言い分が反映されなかった
	- CrowDEAを使った場合：事前に集めた意見からCrowDEAで候補を抽出。「仕事を実行できるか自身がない」という意見に注目が集まり、「何でも言い合える雰囲気づくりが必要」という結論に。
- illumidea
	- 一致比較のコストが問題であったが、LLMによって評価できるように
## パネルディスカッション
- SNSにある情報からわかる「人となり」
	- いいねした記事から性格の予測。記事の数が増えるほど精度アップ
	- 人間に予測させた場合＝10記事分の精度、配偶者に予測させた場合＝250記事分の精度（相関係数0.6）
- 相関係数0.6がどの程度か
	- 活躍度を予測して上位50%を採用した場合、相関係数0.6だと採用したうち30%は平均以下→採用した人数の30%は採用基準を満たさない
	- 「活躍」を定量化するのが難しい。予測誤差以外の要因もありそう
- データ量の問題
	- 大人数のデータを取得するのが難しい一方で、ヒトのパラメータは多次元になる。次元圧縮しないと扱えないが、それでこぼれ落ちてしまう情報もあり難しい
- 認知バイアスを測定してマッチングに反映している話
	- 「バイアスをなくそう」ではなく「バイアスを意識して、それを活かそう／それに気をつけよう」という活かし方
- illumideaについて
	- 匿名性は意識している。話し合いにおいて意見にラベルがつくのに抵抗があるという声が
- 創造性を壊すための3つの方法
	- たくさんの人を集める→社会的手抜き
	- 多様なメンバーで議論する→コミュニケーションが困難
	- リーダーシップを発揮する→促進的なリーダーシップ
- 創造性の高いチームを組織するための3つの方法
	- 意見だけをあつめる。小さなチームにする
	- 多様なメンバーを集める
	- 公平な共創型リーダーシップ
# [[4B1-KS-19] JSAI・共同通信社連携企画「ニュースデータｘAI・知の共創プロジェクト」](https://confit.atlas.jp/guide/event/jsai2025/session/4B01-01/tables?CKiPoPihng)
- AIマップ
	- https://www.ai-gakkai.or.jp/aimap/
- ニュースデータを用いたコンペを実施
- 期待すること
	- AIマップ主要キーワードと繋がりのマップ
	- 社会をあらわすキーワード、社会課題の抽出
	- まだつながりが明確でない（潜在的な）「社会課題」を浮かび上がらせることができるか？
- ニュース記事が読まれた時に想起されるもの（シニフィエ）は時代・文脈で変わる。そこの価値を最大化するようなAI活用ができないか
#  [[4B3-KS-21] 人とAIエージェントの共生・協働 ～生成AIがもたらす社会・産業の変革に向けて～](https://confit.atlas.jp/guide/event/jsai2025/session/4B03-03/tables?gEAEYqAKFQ)
## 人とAIエージェントの共生・協働
- AIエージェント同士のやり取り
	- 企業間での取引条件の交渉・調整
	- AIコンステレーション
	- AIエージェント群による行動シミュレーション
	- 自動交渉AIエージェントが強化学習の結果、談合を始めた
- 研究開発課題
	- Positive面
		- AIの問題解決能力のさらなる高d化
		- マルチエージェント理論高度化
		- 人とAIの相互理解・メンタルモデル
		- マルチエージェント創発理論・実証
		- マルチエージェント経済圏
	- Negative面
		- AIシステミックリスク対策
		- 人・AI共生社会のトラスト基盤
		- AIエージェントと心理・認知
		- AIエージェント計算・通信基盤
- 人・AI共生社会に向けた研究開発ビジョン
	- マルチエージェント研究
	- インタラクション研究
	- AIモデル研究
	- セキュリティ研究
	- コンピューティング研究
	- 人文・社会学研究
## NEC
- 人・AI共生社会はITベンダーにとって巨大なビジネスチャンス
	- 業務用エージェントの実用化
		- 統制されたエージェント間の調整・交渉から統制されていないエージェント間の調整・交渉
	- エージェント経済圏の形成・進展へ（数百兆円＠2030）
		- エージェント（の動作）自体の取引（業務委託、派遣、、）
		- エージェントによる経済活動（売買、投資、融資、、）
		- そのためのサービス（実行基盤、能力検定、研修、、）
	- 人間もエージェントの一種、エージェントも社会の一部
		- エージェント間の相互接続性・相互運用性
		- エージェント利用者だけでなく、エージェント（の提供者）も含めた安全・安心
		- 国際競争力確保のための、XaaA経済圏の育成（制度・技術・インセンティブ）
			- タックスヘイブンのようにAIに法人格を与えるような国も現れるかも
	- 企業間での取引条件調整のための自動交渉
## パーソナルAIエージェントの可能性と展望
- 自分では対処できない問題を自分の利益のために代理的に遂行する
- 自分の意をくんだ高度な情報処理やコミュニケーションを担う
- 自分以上の自分
## 社会的合意形成
- 悪意のあるAI・ユーザー・SNS、善意だが違う目的で意思決定するAI
- AIエージェントの支援による合意形成
- ソフトウェアエージェントと人間が一緒に参加するソーシャルネットワークでの民主主義（ハイパー民主主義）のための合意形成プラットフォーム D-Agree
	- アフガニスタンでの実証実験
- AgenticDemocracy
## 集合的予測符号化（谷口忠大）
- 科学のモデルとしての集合的予測符号化
	- 科学を、集合的予測符号化をする記号創発システムとして捉える科学のモデル
- 集合的予測符号化仮説
	- 言語／記号系の形成は言語ゲームを通じた外的表彰の分散的ベイズ推論に基づく
- 人間とAIを含んだ共生的知能の創生
	- 共生的なAIアラインメント
	- 科学発見の自動化
	- AIを加えた民主的意思決定
	- 身体性言語創発
## LLMの安全性構築に向けて
- NII-LLMC
- 安全性WG活動
	- 安全性データ構築・評価
	- 国際的な活動
- AnswerCarefully version2
	- 1800件の安全性インストラクション
## 社会の安全性の観点
- EU AI法
	- 汎用目的AI（GPAI）も別枠で規制されている
	- システミックリスク
		- 制御不能
		- FLOPで10の25乗より大きい場合はリスク有と推定される
			- 現時点では批判。AIエージェントを想定した転換が必要
	- 規制緩和に向けた見直しがされている
- 信頼（trust）と信頼相当性（trustworthiness）は区別。後者は心理的要素が含まれる
- どこを信頼相当性／信頼の問題として区切るかが研究課題
## 共生AI学際システム
- 人口社会・人口経済の研究者
- 社会が知能を生み出した。社会の無い知能は無い
## 共生AI基盤
- 再現可能な方法論の開発が必要
	- モデルによる結果のばらつき
- 社会問題を生まないAI設計と使用ガイドラインの策定
- 日本の特徴を活かした研究
	- 多言語コラボレーション
	- 詐欺メールの7割が日本を標的
	- 高齢者向けAI介入
	- 男女のジェンダーギャップ解消支援
	- 文化産業の保護とクリエイティブ
	- ツール開発の両立
## パネルディスカッション
- どう箍をはめるか
	- 注意義務・過失に関する議論が
	- 誰も悪くないシステミックリスクに対してはどうするか。トラストアンカーをネットワークにどう入れるか。事業者による消費者保護の観点で考えるべき
	- 頼りすぎると人の能力が落ちていく。人を依存させすぎないAIのデザインも可能なのでは
- 安全性の基準について
	- 社会学などと連携しながら基準を創る必要あり
	- 差別をしてはいけないが「差別」の概念をなくしてしまうのは違う。TPOに応じて振る舞えるような仕組みが入れられると良い
	- アメリカとEUの動向が基準になってしまいがちだが、価値観は多様
	- 価値観はプロパガンダになってしまう（例：Deepseek「尖閣諸島は中国のもの」）。社会と密結合したアラインメントが重要
	- 文化・価値観をどうコーディングするか
	- パーソナルAIではより細分化された文化・価値観になるのでは
	- ローカルLLMが主流な時代が来た場合、アラインメントの話も変わってくる。LLM用のチップとか。そのような社会は来るのか？
	- 民主主義の実装において捨てられてしまった部分をAIが担ってくれるのではないか
	- 意思決定において多数決は多くの問題を含んでいる。限られた時間の中で意思決定するための一つの手段。AIは意思決定のサポートができるのでは
		- 土日に投票に行けない人の代わりにAIエージェントがサポート
		- 議事録の読み込み＆提言
- 人とAIエージェントの共生を数理的にモデリングできるのか
	- ゲームセオリーなど。各プレイヤーが合理的であるという前提。LLMがそこにどう関わってくるか
	- ビブリオバトル
	- スタンフォード大学の研究。ペルソナを持った1000名のLLMのシミュレーションによってダイナミクスを予測できる
- 今後重要な研究課題
	- ヒューマンフレンドリーからAIフレンドリーへの移行
	- 一人ひとりの生きている人間の価値を重要視
	- 個を重視した先のアラインメント。電子のスピードでインタラクションしていくAIとヒトとがどう共生していくか
	- AIの言語出力スピードが上がったら人間がついていけなくなる
	- 共生に関する議論のスピードよりもAIの進化のスピードが早い問題。学術のタイムスケールについてどう考えていくべきか
	- LLMは記憶容量が十億倍になったオウム？
	- スピードについていく一方で、ゆっくり自分と向き合う時間も必要
	- 技術によってスケールの垣根がなくなる。そこで出た課題をまた技術で解決
	- 共生を強制される、大企業によって価値観を押し付けられる。それに対抗するための倫理面の研究が重要
